---
title: "Tarea 7"
author: "Santiago Robatto y Sofia Terra"
format: pdf
editor: visual
---

```{r, message=FALSE, warning=FALSE, echo=FALSE}
#Cargar paquetes
library(bayesrules)
library(tidyverse)
library(rstan)
library(bayesplot)
library(broom.mixed)
library(janitor)
library(ggplot2)
library(knitr)
library(kableExtra)
library(ggplot2)
library(gridExtra)
library(patchwork)
library(posterior)
```

## Ejercicio 8.9 Bayes Rules!

![](8.9letra.png){fig-align="center"}

### Respuestas:

Contexto: estamos trabajando con pruebas de hipótesis, una tarea fundamental en el análisis bayesiano. Este ejercicio tiene el objetivo de funcionar como un acercamiento básico a este tema.

**a.** Primero nos piden calcular la **probabilidad a posteriori de la hipótesis alternativa**. Para ello, calcularemos la probabilidad de que $\pi$ pertenezca al intervalo de la hipotesis alternativa, es decir que sea mayor que 0.4.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#Para pi > 0.4, queremos la cola derecha
#obtenemos la probabilidad a la derecha de pi
#obs: se calcula la cola izquierda de forma predeterminada
post_prob <- pbeta(0.4, 4, 3, lower.tail = FALSE)
post_prob
```

El resultado revela que hay gran evidencia a favor de la hipótesis alternativa. La probabilidad de que $\pi$ será mayor a 0.4 es aproximadamente 82%

**b.** Ahora calculamos las **posterior odds**.

Para ello, realizaremos el cociente entre la probabilidad a posteriori de la hipotesis alternativa y su opuesto.

```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
post_odds <- post_prob / (1 - post_prob)
post_odds
```

Ya sabemos que la probabilidad a posteriori de la alternativa es 0.8202, por lo tanto, nuestra probabilidad posteriori de la hipótesis nula será 1-0.8202 = 0.1792. Entonces:

$$
\text{posterior odds} = \frac{0.8202}{0.1792} \approx 4.58
$$ De esta manera es casi 5 veces más plausible que $\pi$ supere 0.4. Los posterior odds representan nuestra información actualizada con respecto a $\pi$ luego de observar los datos muestreados.

**c.** A continuación, vamos a ver cuáles son nuestros **prior odds**. Primero calculamos la probabilidad a priori de la hipótesis alternativa. Esta es aproximadamente 0.6645:

```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
prior_prob <- pbeta(0.4, 1, 0.8, lower.tail = FALSE)
prior_prob
```

Con este resultado obtenemos que la probabilidad a priori de la nula es aproximadamente 0.3354. Por lo tanto, la prior odds es 1.98. Esto significa que es casi 2 veces más plausible que $\pi$ supere 0.4.

```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
prior_odds <- prior_prob / (1 - prior_prob)
prior_odds
```

**d.** Ahora, vamos a trabajar con el **Factor de Bayes**. Esta medida compara la posterior odds con la prior odds. Nos da información sobre cuánto evolucionó nuestra variable de estudio luego de observar los datos de la muestra.

La fórmula es:

$$
\text{Bayes Factor} = \frac{\text{posterior odds}}{\text{prior odds}} 
$$

```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
BF <- post_odds / prior_odds
BF
```

En nuestro ejercicio, el factor de Bayes es $\approx 2$. Esto implica que al observar la información recabada, la posterior odds es 2 veces más grande que la prior odds. La plausibilidad de la alternativa aumentó, sin embargo, no lo hizo a gran escala. Para que hubiera mayor evidencia sobre la alternativa, el factor de Bayes debería ser mucho más alto. Como punto de comparación, en el ejemplo del capítulo 8 de Bayes Rules!, el factor de bayes que se obtiene es 60, aportando este gran evidencia sobre la hipótesis alternativa.

**e.** **Explicación cualitativa de los resultados:**

En este ejercicio queríamos evaluar la probabilidad de que el parámetro $\pi$ sea mayor o menor que 0.4, y para eso realizaremos las cuentas antes y despues de mirar nuestros datos.

Antes de observar los datos, nuestras creencias estaban representadas por una distribución Beta(1, 0.8), lo que reflejaba una ligera inclinación hacia valores grandes de $\pi$.

Luego, al incorporar los datos, nuestra creencia se actualizó a una Beta(4, 3).A partir de esa nueva información (posterior), la probabilidad de que $\pi$ sea mayor a 0.4 aumentó considerablemente;lo que implica que los datos brindaron evidencia a favor de que $\pi$ efectivamente es mayor que 0.4.

Lo que buscamos con este ejercicio es saber si la información que recolectamos sobre nuestro estudio apoya nuestra hipótesis alternativa, la "idea" que queremos probar como verdadera, en contraste con la hipótesis nula, la que queremos rechazar. Para obtener una conclusión adecuada calculamos primero la probabilidad de nuestra distribución a posteriori (nuestra información actualizada luego de llevar a cabo la investigación), la probabilidad de la distribución a priori (nuestra información inicial, nuestra "base") y luego las comparamos haciendo el cociente entre ellas. Esto nos mostró que nuestra creencia sobre la veracidad de la hipótesis alternativa aumentó. Si bien no fue de forma pronunciada, ahora tenemos mayor evidencia sobre la idea que queremos probar como cierta.

\newpage

## Ejercicios 8.14

![](8.14letra.png){fig-align="center"}

**a.** Se considera como más apropiado el modelo Beta-Binomial dado que estamos trabajando con una proporción.

Por un lado sabemos que $\pi$ representa la proporcion de adultos que no cree en el cambio climatico. Para aprender sobre $\pi$, se utiliza información de una encuesta de n adultos, y se cuenta el número de estos que no cree en el cambio clímatico, al cual llamamos Y.

Teniendo en cuenta que nuestro objetivo es saber si un adulto americano cree o no en el cambio climático, podemos utilizar una variable Bernouilli para realizar el modelo. La misma vale 0 cuando la persona cree en el cambio climático 1 y vale 0 si la persona no cree.

Por otro lado, como tenemos una población de n adultos, hacemos la sumatoria de todos estos casos, lo cual distribuye de manera binomial. Al no ser constante la probabilidad de "éxito" (que no crea), conjugamos la binomial a un modelo beta, el cual nos proporcionará la distribución de la probabilidad de "éxito".

**b.** Buscamos definir el modelo a priori de $\pi \sim \text{Beta}(\alpha, \beta)$, donde $\alpha$ es el número de "éxitos" y $\beta$ es el número de "fracasos".

Al no tener información previa, se pueden considerar tres situaciones diferentes:

1.  $\pi \sim \text{Beta}(1, 1)$: En este punto somos completamente neutrales al respecto de la distribución de $\pi$, asignandole igual probabilidad a todos los valores entre 0 y 1. De cierta manera estamos diciendo que la cantidad de "éxitos" y "fracasos" es la misma.
2.  $\pi \sim \text{Beta}(\alpha, \beta > \alpha)$, por ejemplo $\text{Beta}(1,5)$ En este caso tenemos la creencia de que pocas personas creen que el cambio climático es falso. Esperamos que haya más "fracasos" que "éxitos".
3.  $\pi \sim \text{Beta}(\alpha, \beta < \alpha)$ Por ejemplo $\text{Beta}(5, 1)$: Finalmente, aquí consideramos lo contrario a lo anterior. Muchas personas creen que es falso. Hay más "éxitos" que "fracasos".

Creemos que la más adecuada de todas estas es la segunda, ya que el cambio climático es un fenómeno que está ampliamente considerado por la población como cierto. En general, son pocos los que lo consideran como no existente.

**c.** Ahora se aclara que se trabajará con una $\text{Beta}(1, 2)$, se utilizará esa priori definida por el autor. La misma sigue una tendencia similar a la especificada en la pregunta anterior, ambas tienen la creencia, o "información base" de que hay más personas que creen en el cambio climático, que las que no creen. Sin embargo, la dada por el libro no es tan extrema como la definida en la pregunta b. Aquí hay menos "fracasos" que en la otra distribución Beta.

**d.**

```{r, message=FALSE, warning=FALSE, echo=FALSE}
#Tenemos que cargar los datos
data("pulse_of_the_nation")
```

Vamos a trabajar con los datos de pulse_of_the_nation, del paquete bayesrules. Si filtramos por creencias sobre cambio climático obtenemos la siguiente tabla:

```{r, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
datos_climate_change <- pulse_of_the_nation %>%
  group_by(climate_change) %>% #agrupamos por las creencias sobre CL
  tally()

kable(datos_climate_change, caption = "Resumen de opiniones:") %>%
  kable_styling( #Estilo de la tabla
    bootstrap_options = c("striped", "hover"), 
    full_width = FALSE
  )
```

Observamos que 150 personas consideran que la existencia del cambio climático es falsa. Estos son nuestros "éxitos". Si calculamos la proporción entre el total de encuestados obtenemos: $150/1000=0.15$. Esto es un 15% de la población encuestada.

**e.** Tenemos que nuestro modelo inicial es:

$$Y | \pi \sim \text{Bin}(1000, \pi)$$ $$\pi \sim \text{Beta}(1, 2)$$

Por lo tengo, al haber observado que $Y=150$, nuestro modelo posteriori queda de la siguiente manera:

$$\pi | (Y=y) \sim \text{Beta}(\alpha_{\text{prior}} + y, \quad \beta_{\text{prior}} + (n - y))$$ Si sustituimos los datos que tenemos obtenemos:

$$\pi | (Y=y) \sim \text{Beta}(1 + 150, 2 + (1000 - 150))$$ $$\pi | (Y=y) \sim \text{Beta}(151, 852)$$ La función de densidad posteriori queda de la forma:

$$
f(\pi | y = 150) = \frac{\Gamma(151 + 852)}{\Gamma(151)\Gamma(852)} \pi^{151-1} (1 - \pi)^{852-1} \quad \text{for } \pi \in [0, 1].
$$

Nuestro modelo graficado es el siguiente:

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_beta_binomial(alpha = 151, beta = 852, y = 150, n = 1000)  +
   coord_cartesian(xlim = c(0.10, 0.20)) #se ajusta la escala 
```

Observación: se ve de esa forma, como "cortado" ya que se tuvo que ajustar el eje de coordenadas, hubo que arreglar la escala porque si no, no se visualizaba bien. Ocurre lo mismo en el próximo gráfico, donde se observa el intervalo de confianza del 95% para $\pi$.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
plot_beta_ci(151,852,0.95) + #función específica para calcular intervalos de confianza
 coord_cartesian(xlim = c(0.10, 0.20)) #ajuste de escala
```

```{r, warning=FALSE, message=FALSE, echo=FALSE, results='hide'}
qbeta(c(0.025, 0.975), 151, 852) #función de quantiles del libro 
```

Tenemos los percentiles 2.5 y 97.5, los cuales son aproximadamente 0.129 y 1.733. Estos nos marcan el 95% de los valores posterioris plausibles de $\pi$. El intervalo de confianza resultante para $\pi$ es (0.129, 1.733), el mismo que se visualiza en el gráfico, representado por la zona pintada de celeste. El área de esta región, por lo tanto, la fracción de valores que "caen" en la misma, es 0.95. Esto nos muestra una interpretación más intuitiva sobre el intervalo de confianza. Hay una confianza del 95% de que entre el 12.9% y el 17.33% de los adultos americanos crea que la existencia del cambio climática es falsa. Si bien se calculó el intervalo de confianza del 95%, esta no es la única opción, no existe un intervalo de confianza "correcto". Dependiendo del contexto se usará uno u otro. En este caso, uno del 95% es adecuado.

Observación: como fue mencionado, estamos calculando el área celeste:

$$
P(\pi \in (0.129, 1.733) | Y = 150) = \int_{0.129}^{1.733} f(\pi | y = 150) d\pi = 0.95.
$$

\newpage

## Ejercicio 8.15

![](8.15letra.png){fig-align="center"}

**a.** Como observamos que la mayoría de la función de densidad posteriori cubre un espacio mayor a 0.1 y que el intervalo de confianza es mayor que 0.1, se rechaza la hipótesis nula, esto es, que la proporción de adultos americanos que cree que el cambio climático no existe es menor o igual al 10%.

**b.** Para calcular exactamente qué tan plausible es que $\pi > 0.1$, podemos calcular la probabilidad posteriori de este caso específico:

$$
P(\pi > 0.1 | Y = 150) = \int_{0.129}^{1.733} f(\pi | y = 150) d\pi
$$ Podemos calcular esta probabilidad con la función pbeta():

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# probabilidad posteriori de que pi > 0.1
post_prob2 <- pbeta(0.1, 151, 852, lower.tail = FALSE)
post_prob2
```

Esto es aproximadamente 1, lo que significa de que casi se puede asegurar por completo que la probabilidad de que más del 10% de las personas cree que el cambio climático es falso.

**c.** Ahora queremos calcular el Factor de Bayes, lo hacemos de la misma forma que en el ejercicio 8.9, calculando las posterior odds y las prior odds y haciendo el cociente entre ellas. (ver archivo .qmd)

```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
post_odds2 <- post_prob2 / (1 - post_prob2)
post_odds2
```

```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
prior_prob2 <- pbeta(0.1, 1, 2, lower.tail = FALSE)
prior_prob2
```

```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
prior_odds2 <- prior_prob2 / (1 - prior_prob2)
prior_odds2
```

```{r, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
BF2 <- post_odds2 / prior_odds2
BF2
```

Obtenemos que el factor de bayes es aproximadamente 750017. Esto significa que los datos de la muestra de 1000 personas proveen evidencia de que es \~750.000 veces más fuerte a favor de la hipótesis alternativa ($\pi > 0.1$) contra la hipótesis nula ($\pi <= 0.1$). Hay gran evidencia sobre que más del 10% de la población no cree en el cambio climático.

**d.** Se concluye que la proporción de adultos que no cree en el cambio climático es mucho menor que la creída inicialente.

Inicialmente, realizando un contraste de hipótesis se mostró que se rechazó la hipótesis nula, por lo tanto se penso que la proporción era mayor al 10%. Asimismo, se calculó un intervalo de confianza, en cual se midió que con 95% de confianza que dicha proporción sería entre 0.129 y 1.733 (observar que la media posterior es de 0.15). Luego, al muestrear la poblacion, se actualizó la información. Notar que la priori que seleccionamos en la parte b del ejercicio 8.14 era mucho más acertada que la dada por el autor del libro. En nuestra priori la proporción era de \~16%, mucho menor que el \~33% dado proporcionado por el libro. Esto indica que nos encontrabamos más informados sobre el tema que el autor.

\newpage

## Ejercicio 8.16

![](letra8.16.png){fig-align="center"} Procederemos a simular la proporcion $\pi$ con Rstan. Para ello definiremos el modelo:

```{r, message=FALSE}
bb_model <- "
  data {
    int<lower = 0, upper = 1000> Y;
  }
  parameters {
    real<lower = 0, upper = 1> pi;
  }
  model {
    Y ~ binomial(1000, pi);
    pi ~ beta(1, 2);
  }
  "
```

Con ste modelo, correremos las cadenas y graficaremos sus principales graficos:

```{r, include=FALSE}
bb_sim <- stan(model_code = bb_model, data = list(Y = 150), 
               chains = 4, iter = 5000*2, seed = 84735)
```

```{r, fig.width=12, fig.height=8, fig.align='center', echo=FALSE}
traza <- mcmc_trace(bb_sim, pars = "pi", size = 0.1)

densoverlay <- mcmc_dens_overlay(bb_sim, pars = "pi") + 
  ylab("density")

hist <- mcmc_hist(bb_sim, pars = "pi") + 
  yaxis_text(TRUE) + 
  ylab("density")

dens <- mcmc_dens(bb_sim, pars = "pi") + 
  yaxis_text(TRUE) + 
  ylab("density")

(traza + densoverlay) / (hist + dens)
```

En la traza se observa un comportamiento deseado, donde aparantemente todas estas se mezclaron correctamente y donde tampoco se observa ninguna considerablemente distinta al restos. Procederemos a graficarlas luego por separado para asegurarnos que efectivamente esto haya sido asi.

En el gráfico de densidades se aprecia que las cuatro cadenas producen distribuciones prácticamente iguales, superponiendose entre elleas. Al observarlas superpuestas se visualiza claramente que todas convergen hacia la misma distribución posterior, lo que refuerza la evidencia de estabilidad mencionada y homogeneidad entre cadenas que mencionamos al mirar las trazas.

El histograma muestra la distribución empírica de los valores simulados de $\pi$, con una forma aproximadamente simétrica y unimodal entorno a 0.150, que era la proporcion inicial. Esto sugiere que las muestras extraídas representan de manera adecuada la forma de la distribución posterior.

Por último, la densidad suavizada resume la distribución total combinando todas las cadenas. Su forma es continua y bien definida, tambien unimodal, simetrica y centrada entornoa 0.150, lo que confirma que el muestreo fue eficiente y que el parámetro $\pi$ se encuentra bien modelado.

Procederemos a mirar las cadenas por separado:

```{r,  echo=FALSE}
cadenas <- extract(bb_sim, permuted = FALSE)
pi_cadenas <- cadenas[, , "pi"]

p1 <- ggplot(data.frame(iter = 1:nrow(pi_cadenas),
                        value = pi_cadenas[, 1]),
             aes(x = iter, y = value)) +
  geom_line(color = "steelblue") +
  labs(title = "Cadena 1",
       x = "Iteración", y = expression(pi)) +
  theme_minimal()

p2 <- ggplot(data.frame(iter = 1:nrow(pi_cadenas),
                        value = pi_cadenas[, 2]),
             aes(x = iter, y = value)) +
  geom_line(color = "steelblue") +
  labs(title = "Cadena 2",
       x = "Iteración", y = expression(pi)) +
  theme_minimal()

p3 <- ggplot(data.frame(iter = 1:nrow(pi_cadenas),
                        value = pi_cadenas[, 3]),
             aes(x = iter, y = value)) +
  geom_line(color = "steelblue") +
  labs(title = "Cadena 3",
       x = "Iteración", y = expression(pi)) +
  theme_minimal()

p4 <- ggplot(data.frame(iter = 1:nrow(pi_cadenas),
                        value = pi_cadenas[, 4]),
             aes(x = iter, y = value)) +
  geom_line(color = "steelblue") +
  labs(title = "Cadena 4",
       x = "Iteración", y = expression(pi)) +
  theme_minimal()

p1+p2+p3+p4
```

Las trazas correspondientes a las cuatro cadenas muestran un comportamiento estable y sin tendencia, oscilando alrededor de 0.150, que es la proporcion obtenida anteriormente. Dado que se centran en este valor y no se observan estancamientos ni saltos abruptos, nos damos cuenta que las cadenas han alcanzado la zona estacionaria y presentan buena mezcla. En conjunto, las trazas son sanas, por lo que los resultados posteriores pueden considerarse representativos.

Si comparamos el histograma con la densidad teorica que hallamos anteriormente:

```{r, fig.align='center', echo=FALSE, fig.width=5, fig.height=3, fig.align='center'}
p <- mcmc_dens(as.matrix(bb_sim, pars = "pi"))
dens_mcmc <- density(as.matrix(bb_sim)[, "pi"])
max_mcmc <- max(dens_mcmc$y)
p + stat_function(
  fun = function(x) dbeta(x, shape1 = 151, shape2 = 852) * (max_mcmc / max(dbeta(seq(0,1,0.001), 151, 852))),
  color = "red",
  linetype = "dashed",
  linewidth = 1
) +
  labs(
    title = "Comparación: Aproximación MCMC vs. Posterior Teórico",
    subtitle = "La curva roja punteada representa la densidad teórica Beta(151, 852)"
  )
```

Facilmente se observa que los datos simularon correctamente el modelo.

**Parte c**.

El **rhat** es una medida que compara la convergencia entre cadenas. Basicamente compara la convergencia dentro de cada una de las cadenas con la variabilidad entre ellas. Si todas las cadenas convergieron a lo mismo, que es lo que queremos, el rhat sera aproximadamente 1.

Por otro lado tenemos el **neff_ratio**, que es una medida que mira la independencia entre valores. Tiene que ver con la autocorrelacion de la cadena, y buscamos que sea lo mas alta posible. Ademas es util para estimar cuantos de mis valores simulados son efectivamente independientes.

En este caso no contamos explicitamente con el neff_ratio, sino que lo calcularemos calculando el ess_bulk sobre n. El **ess_bulk** es la estimacion la cantidad de valores que fueron muestreados de forma independiente:

```{r, echo=FALSE}

draws <- as_draws_df(bb_sim)
resumen <- summarise_draws(draws)[, c("variable", "rhat", "ess_bulk")]
resumen <- subset(resumen, variable != "lp__", select = c("variable", "rhat", "ess_bulk"))

# mostrar en tabla
kable(resumen, caption = "Rhat y ess_bulk  para mu")
```

Por lo tanto, al ser el rhat tan cercano a 1 concluimos que cada una de las cadenas tuvo buena convergencia.

Por otro lado, el neff_ratio es:

$$\text{ESS ratio} = \frac{N_{\text{eff}}}{N} = \frac{7370}{20000}  = 0.3685$$

Esto nos sugiere que 7370 valores aproximadamente son independientes, o de otra manera, casi el 37% de los valores fueron independientes.

Para confirmarlo, podemos graficar la auto-relacion de la cadena:

```{r, echo=FALSE}
library(bayesplot)
mcmc_acf(as.array(bb_sim), pars = "pi", lags = 10)
```

Se observa que para unn lag de 4, en todas las cadenas la autocorrelacion es practicamente nula.

\newpage

## Ejercicio Gibbs Sampling: análisis de sensibilidad a los hiperparámetros.

Buscamos comparar cómo nuestros resultados al utilizar Gibbs Sampling se ven afectados dependiendo de los valores de nuestros hiperparámetros. Vamos a considerar tres casos: los valores iniciales dados por el problema, valores poco informativos y valores muy informativos.

Observación: Una priori no informativa es más débil, tiene una varianza muy grande. No se tiene una creencia fuerte. En cambio, una priori informativa sí es fuerte y tiene varianza muy baja.

Lo que haremos será ejecutar el código proporcionado por el docente y se irán guardando todos los resultados en una tabla, la cual hará la visualización de las diferencias más clara.

Este paso es fundamental para comprender la robustez del modelo. Si pequeñas variaciones en los hiperparámetros generan grandes cambios en los resultados, significa que el modelo depende fuertemente de las creencias previas y es menos estable. Si, en cambio, los resultados se mantienen similares, indica que la información proviene principalmente de los datos y que la elección de los hiperparametros no rompe las conclusiones que podamos obtener.

De esta manera:

```{=tex}
\begin{itemize}
  \item \textbf{$\theta_0$} — Controla la \textit{media previa de $\theta$}.  
  Es lo que a priori creemos que vale el promedio logarítmico de los datos.  
  Es como decir: “Antes de ver los datos, creo que $\theta$ está cerca de este valor.”

  \item \textbf{$\tau^2$} — Controla la \textit{varianza previa de $\theta$}.  
  Indica cuán fuerte es esa creencia:  
  \begin{itemize}
    \item Si $\tau^2$ es grande $\rightarrow$ prior débil (creencia difusa, abierta a aprender de los datos).  
    \item Si $\tau^2$ es chica $\rightarrow$ prior fuerte (estás muy convencido de $\theta_0$).  
  \end{itemize}

  \item \textbf{$\alpha$ y $\beta$} — Dan forma a la \textit{distribución a priori de $\sigma^2$}.  
  Cuanto más grandes son, más “informativa” y concentrada es la creencia sobre la varianza:  
  \begin{itemize}
    \item Si $\alpha = \beta = 0.1$ $\rightarrow$ prior muy débil.  
    \item Si $\alpha = \beta = 10$ $\rightarrow$ prior muy fuerte.  
  \end{itemize}
\end{itemize}
```
Utilizaremos los siguientes valores para realizar la comparación:

| Caso | $\alpha$ | $\beta$ | $\tau^2$ | $\theta_0$ | ¿Qué se evalúa?                                                                                             |
|---------|---------|---------|---------|---------|---------------------------|
| 1    | 3.0      | 3.0     | 10.0     | 5.0        | Valores iniciales del problema (neutrales)                                                                  |
| 2    | 0.1      | 0.1     | 10.0     | 5.0        | Valores no informativos sobre $\tau^2$                                                                      |
| 3    | 10.0     | 10.0    | 10.0     | 5.0        | Valores informativos sobre $\tau^2$                                                                         |
| 4    | 3.0      | 3.0     | 100.0    | 5.0        | Valores no informativos sobre $\theta_0$                                                                    |
| 5    | 3.0      | 3.0     | 0.1      | 5.0        | Valores informativos sobre $\theta_0$                                                                       |
| 6    | 3.0      | 3.0     | 10.0     | 6.6        | Utilización de la media (theta0 está centrada en los datos dados)                                           |
| 7    | 3.0      | 3.0     | 10.0     | 0.0        | Valor de $\theta_0$ que muestra una creencia sobre que el hiperparámeto no está centrado en los datos dados |

<<<<<<< HEAD
| Caso | alpha | beta | tau\^2 | theta0 | ¿Qué se evalúa? |
|----|----|----|----|----|----|
| 1 | 3.0 | 3.0 | 10.0 | 5.0 | Valores iniciales del problema (neutrales) |
| 2 | 0.1 | 0.1 | 10.0 | 5.0 | Valores no informativos de tau\^2 |
| 3 | 10.0 | 10.0 | 10.0 | 5.0 | Valores informativos de tau\^2 |
| 4 | 3.0 | 3.0 | 100.0 | 5.0 | Valores no informativos de theta0 |
| 5 | 3.0 | 3.0 | 0.1 | 5.0 | Valores informativos de theta0 |
| 6 | 3.0 | 3.0 | 10.0 | 6.6 | Utilización de la media (theta0 está centrada en los datos dados) |
| 7 | 3.0 | 3.0 | 10.0 | 0.0 | Valor de theta0 que muestra una creencia sobre que el hiperparámeto no está centrado en los datos dados |
=======
Nota: las tablas se realizaron con la función de crear tablas de Quarto.

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
### Ejemplo 7.3, pp.202-205
rm(list=ls())

# Datos del ejemplo p.204
x <- c(91, 504, 557, 609, 693, 727, 764, 803, 857,
       929, 970, 1043, 1089, 1195, 1384, 1713)
lx <- log(x) # transformación logarítmica

# Valores asignados a los hiperparámetros en la 
# Figura 7.2, p.205
a <- 3
b <- 3
tau2 <- 10
theta0 <- 5
```

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
# Implementación del muestreador de Gibbs
Nsim = 5000 # número de iteraciones en Figura 7.2, p.205
xbar <- mean(lx); xbar
n <- length(lx); n
sh1 <- (n/2) + a; sh1
sigma2 <- theta <- rep(0, Nsim)
```

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
set.seed(108)
# Valores iniciales
sigma2[1] <- 1/rgamma(1, shape=a, rate=b)
B <- sigma2[1]/(sigma2[1] + n*tau2)
theta[1] <- rnorm(1, mean=B*theta0 + (1-B)*xbar, sd=sqrt(tau2*B))

for (i in 2:Nsim){
  B <- sigma2[i-1]/(sigma2[i-1] + n*tau2)
  theta[i] <- rnorm(1, mean=B*theta0 + (1-B)*xbar, sd=sqrt(tau2*B))
  ra1 <- (1/2)*(sum((lx-theta[i])^2)) + b
  sigma2[i] <- 1/rgamma(1, shape=sh1, rate=ra1)
}

# theta contiene los 5000 valores simulados de θ
sigma <- sqrt(sigma2) # sigma contiene los 5000 valores simulados de σ
```

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
set.seed(108)
# Intervalos de credibilidad aproximados del 90%
q_theta <- quantile(theta, c(0.05, 0.95))
q_sigma <- quantile(sigma, c(0.05, 0.95))
cat("Intervalo del 90% para θ:", round(q_theta, 3), "\n")
cat("Intervalo del 90% para σ:", round(q_sigma, 3), "\n")
```

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
set.seed(108)
# Medias a posteriori
cat("Media a posteriori de θ:", round(mean(theta), 3), "\n")
cat("Media a posteriori de σ²:", round(mean(sigma2), 3), "\n")
cat("Media a posteriori de σ:", round(mean(sqrt(sigma2)), 3), "\n")
```

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
set.seed(108)
# Crear data frames para ggplot
df_theta <- data.frame(theta = theta)
df_sigma <- data.frame(sigma = sigma)
df_sigma2 <- data.frame(sigma2 = sigma2)

```

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
set.seed(108)
# Histograma para θ
p_theta <- ggplot(df_theta, aes(x = theta)) +
  geom_histogram(aes(y = after_stat(count)), 
    color = "black", fill = "lightgray", bins = 40) +
  labs(title = expression(theta),
       x = "", y = "Frecuencia") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 14))

```

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
set.seed(108)
# Histograma para σ
p_sigma <- ggplot(df_sigma, aes(x = sigma)) +
  geom_histogram(aes(y = after_stat(count)), 
    color = "black", fill = "brown3", bins = 40) +
  labs(title = expression(sigma),
       x = "", y = "Frecuencia") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 14))

```

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
set.seed(108)
# Histograma para σ²
p_sigma2 <- ggplot(df_sigma2, aes(x = sigma2)) +
  geom_histogram(aes(y = after_stat(count)), 
    color = "black", fill = "lightblue", bins = 40) +
  labs(title = expression(sigma^{2}),
       x = "", y = "Frecuencia") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 14))
```

```{r, message=FALSE, warning=FALSE, results='hide', echo=FALSE, fig.show='hide'}
set.seed(108)
# Histogramas para θ y σ
grid.arrange(p_theta, p_sigma, ncol = 2)
# Histogramas para θ y σ²
grid.arrange(p_theta, p_sigma2, ncol = 2)
```

Evaluando los valores de los hiperparámetros en cada caso se obtiene la siguiente tabla de resultados:

<<<<<<< HEAD
| Caso | Media a posteriori de theta | Media a posteriori de sigma | Intervalo de Confianza del 90% para theta | Intervalo de Confianza del 90% para sigma |
|----|----|----|----|----|
| 1 | 6.622 | 0.797 | (6.290 ; 6.945) | (0.615 ; 1.039) |
| 2 | 6.220 | 0.696 | (6.333 ; 6.908) | (0.510 ; 0.948) |
| 3 | 6.230 | 0.888 | (6.257 ; 6.987) | (0.727; 1.091) |
| 4 | 6.628 | 0.797 | (6.295 ; 6.953) | (0.615 ; 1.039) |
| 5 | 6.049 | 0.948 | (5.637 ; 6.409) | (0.688 ; 1.308) |
| 6 | 6.628 | 0.797 | (6.297 ; 6.953) | (0.615 ; 1.039) |
| 7 | 6.601 | 0.798 | (6.269 ; 6.924) | (0.616 ; 1.041) |
=======
| Caso | ¿Qué se evalúa?                                                                                             | Media a posteriori de $\theta$ | Media a posteriori de $\sigma$ | Intervalo de Confianza del 90% para $\theta$ |
|---------------|---------------|---------------|---------------|---------------|
| 1    | Valores iniciales del problema (neutrals)                                                                   | 6.622                          | 0.797                          | (6.290 ; 6.945)                              |
| 2    | Valores no informativos sobre $\tau^2$                                                                      | 6.220                          | 0.696                          | (6.333 ; 6.908)                              |
| 3    | Valores informativos sobre $\tau^2$                                                                         | 6.230                          | 0.888                          | (6.257 ; 6.987)                              |
| 4    | Valores no informativos sobre $\theta_0$                                                                    | 6.628                          | 0.797                          | (6.295 ; 6.953)                              |
| 5    | Valores informativos sobre $\theta_0$                                                                       | 6.049                          | 0.948                          | (5.637 ; 6.409)                              |
| 6    | Utilización de la media ($theta_0$ está centrada en los datos dados)                                        | 6.628                          | 0.797                          | (6.297 ; 6.953)                              |
| 7    | Valor de $\theta_0$ que muestra una creencia sobre que el hiperparámeto no está centrado en los datos dados | 6.601                          | 0.798                          | (6.269 ; 6.924)                              |

Antes de comentar el analisis, se calculara la media de los datos y su desvio estandar. Esto sera util para poder evaluar que tan parecido a las observaciones es nuestro posterior obtenido.

```{r, echo=FALSE}
tabla_aux<-data.frame(
  Nombres=c("Media de theta0", "Desvio estandar de sigma"),
  Valores=c(mean(lx), sd(lx))
)
kable(tabla_aux, caption= "Resumen Observaciones")
```

En primer lugar se observa que en todos los casos, la media oscila entre 6.0 y 6.6, independientemente de los distintos hiperparametros que hayamos tomado en cada uno de los ejemplos. Esto sugiere cierta consistencia en los datos y del modelo. Teniendo en cuenta que estamos trabajando con un vector de tan solo 16 observaciones, podemos pensar que el modelo es bueno dado que no necesita un tamano demasiado grande para converger al posterior. En otras palabras, este Gibbs Sampling converge hacia resultados consistentes incluso cuando las creencias iniciales difieren, lo que es una señal de estabilidad del modelo.

Como era de esperar en el **caso 1**, donde los hiperparametros son $\alpha=3$, $\beta=3$ y $\tau^2=10$ , el posterior es parecido a las observaciones.

Sera util como escenario base, donde el posterior se centra muy cerca de la media observada de posterior (6.6) y el desvío (0.8) es prácticamente igual al de los datos. Refleja una buena calibración del modelo: la información de los datos domina, y las creencias previas no sesgan significativamente los resultados.

En el **caso dos**, al reducir $\alpha \ \text{y} \ \beta$ debilitamos la creencia previa sobre $\sigma^2$, lo que refleja incertidumbre sobre la dispersión.

Esto genera una leve caida con respecto a la media de $\theta_0$ y crece la varianza. Este ultimo efecto era sumamente esperable, dado que el prior no aporta ninguna seguridad

Asimismo, utilizando el código proporcionado por el profesor, también se pueden hacer gráficas para visualizar cada caso. Podemos verlo en la siguiente imagen, ordenadas por caso de izquierda a derecha.

![](valoreship.png){fig-align="center" width="980"}

Por otro lado, también se pueden visualizar dos casos más distintivos: uno donde todos los valores de los hiperparámetros son poco informativos y otro donde todos los valores de los hiperparámetros son muy informativos.

**Primer caso**: Una priori muy poco informativa.

Aquí, $\alpha$=$\beta$=0.1, $\tau^2$=100.0, y $\theta_0$=0.0. Obtenemos:

Media de posteriori de $\theta$=6.625.

Media de posteriori de $\sigma$=0.696

Intervalo de confianza al 90% para $\theta$: (6.341 ; 6.911)

Intervalo de confianza al 90% para $\sigma$: (0.510 ; 0.947)

El histograma es el siguiente: ![](histpocainfo.png){fig-align="center"}

**Segundo caso**: Una priori muy informativa.

Aquí, $\alpha$=$\beta$=10.0, $tau\^2$=0.1, y $theta_0$=6.6. Obtenemos:

Media de posteriori de $\theta$: 6.621

Media de posteriori de $\sigma$: 0.883

Intervalo de confianza al 90% para $\theta$: (6.326 ; 6.916)

Intervalo de confianza al 90% para $\sigma$: (0.725 ; 1.082)

El histograma es el siguiente:

![](histmuchainfo.png){fig-align="center"}

Ahora volvamos a comparar con nuestro "caso base", los datos neutrales que nos proporcionaron inicialmente:

Aquí, $\alpha$=3.0, $\beta$=3.0, $tau^2$=10.0, y $\theta_0$=5.0. Obtenemos:

Media de posteriori de $\theta$=6.622

Media de posteriori de $\sigma$=0.797

Intervalo de confianza al 90% para $\theta$: (6.290 ; 6.945)

Intervalo de confianza al 90% para $\sigma$: (0.615 ; 1.039)

El histograma es el siguiente:

![](histinfoinicial.png){fig-align="center"}
